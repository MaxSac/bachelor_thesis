\chapter{Gamma/Hadron-Separation mit gemessenen Daten}
Ziel der Gamma/Hadron-Separation ist es, die von einem Tscherenkow-Teleskop gemessenen Ereignisse den beiden Klassen Signal (Gamma) und Untergrund (Proton) zuzuordnen.
Mit den klassifizierten Gamma-Ereignissen kann dann zum Beispiel der Fluss einer Quelle im Bereich der Gammastrahlung berechnet werden.

Für die Separation zwischen elektromagnetischen und hadronischen Schauern muss ein Modell anhand eines klassifizierten Datensatzes trainiert werden.
Dazu wird zunächst mit der Software \texttt{FACT-Tools} \cite{Bockermann} ein klassifizierter Datensatz prozessiert, um die Rohdaten zu kalibrieren und Attribute zu generieren.
%Ziel der Arbeit ist es die Monte-Carlo simulierten Protonen durch gemessene zu ersetzen.
Ziel der Arbeit ist es zu untersuchen, ob die Gamma/Hadron-Separation durch die Verwendung von gemessenen statt simulierten Untergrunddaten im Trainingsdatensatz verbessert werden kann.

Es ist bekannt, dass die Verteilungen der Attribute auf simulierten und gemessenen Daten nicht vollständig übereinstimmen.
Dieses Problem wird Daten-Monte Carlo-Mismatch genannt.
Durch die Verwendung des gemessenen Untergrunds anstelle der simulierten Protonen soll der Mismatch minimiert und die Klassifikation verbessert werden.
%Da gemessene Protonen besser als simulierte den Untergrund wiedergeben, besteht die Idee, die Klassifikation dadurch zu optimieren.
Bei ähnlichen Experimenten, wie zum Beispiel MAGIC \cite{magic} hat sich diese Methode bereits bewährt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./tikz/motiv/motiv.pdf}
  \caption{Analysekette zur Evaluation der Trainingsmethoden.}
\end{figure}
Zur Überprüfung dieser Methode werden ein \texttt{Random Forest}, sowie ein \texttt{XGBoost Classifier} der Tiefe eins trainiert und optimiert.

Das Trennvermögen der auf den beiden unterschiedlichen Datensätzen trainierten Modelle wird anhand der Receiver Operating Characteristic gemessen.

Des weiteren wird die Signifikanz von zwei verschiedenen Quellen berechnet, die durch zwei unterschiedlich trainierte Modelle gefunden werden. 
Anhand der maximalen Signifikanzen werden die Modelle verglichen.
\section{Erstellen des gemessenen Untergrunds}
\label{sec:makeUnter}
Aufgrund der geringen Spiegelfläche und der damit verbundenen geringen Auflösung betreibt FACT hauptsächlich Langzeitstudien von bekannten, hellen Quellen und alarmiert andere Experimente bei ungewöhnlich hohen Flussraten.
Um die Observationszeit zu maximieren, nimmt FACT dafür Daten im Wobble Modus auf. 
Dabei muss die Kamera nicht extra auf Off-Positionen gerichtet werden und kann dementsprechend effizienter in derselben Zeit arbeiten. 
Dies hat zur Folge, dass keine gemessenen reinen Untergrunddaten existieren. 

Für die Erstellung eines alternativen Protonendatensatzes müssen aus dem Datensatz einer Quellobservation die Protonenereignisse heraussepariert werden. 
Dies wird mit einem Schnitt in $\theta^{2}$ realisiert.
Denkbar wäre auch einen maschinellen Lerner die Gamma-Ereignisse in dem gemessenen Untergunddatensatz heraus separieren zu lassen.
Allerdings würden hier die Monte Carlo-Mismatches erneut eingehen. 
Aus diesem Grund kann darauf verzichtet werden.

Dementsprechend wird anhand des trennstärksten Attributs $\theta^{2}$ versucht, die Region um die bekannte Gamma-Quelle herauszuschneiden, um einen möglichst reinen Untergrunddatensatz zu prozessieren. 
Die Trennstärke des trennstärksten Parameters $\theta^{2}$ im Vergleich zu allen anderen verfügbaren Parametern ist in Abbildung~\ref{fig:roc} dargestellt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Plots/theta_cut.pdf}
  \caption{$\theta^{2}$ Verteilung von simulierten Gamma- und Protonen-Ereignissen, sowie das Verhältnis von Gamma- zu Protonen-Ereignissen.}
  \label{fig:thetacut}
\end{figure}
Durch einen Schnitt auf der $\theta^{2}$-Verteilung soll ein möglichst reiner Datensatz erstellt werden. 
In Abbildung~\ref{fig:thetacut} sind für Proton- und Gamma-Ereignisse die $\theta^{2}$-Verteilungen der Monte Carlo-Simulationen aufgetragen. 
Für kleine $\theta^{2}$-Werte ist das Gamma-Signal um ein Vielfaches größer und nimmt für größer werdende $\theta^{2}$-Werte kontinuierlich ab. 
Ab einem $\theta^{2}$-Wert von \num{0.5} ist das Signal-Untergrund-Verhältnis um ein Zehntel kleiner.
Da der wahre Untergrund sowohl aus Hadronen als auch aus wenigen diffusen Gammaquanten besteht, ist zu erwarten, dass die vereinzelt verbleibenden Gamma-Ereignisse die Klassifizierer nicht weiter negativ beeinflussen.

% Zu beachten ist das Protonen zwar isotrop verteilt seien sollten, jedoch bei zu großen $\theta^{2}$-cuts die Detektoreigenschaften singnifikant werden. Um zu überprüfen inwiefern die Detektoreigenschaften vernachlässigt werden können ist in Abbildung~\ref{fig:corrtheta} die Signifikanz in Abhängigkeit des Parameters $\theta^{2}$ dargestellt.
Um zu überprüfen, ob die trainierten Modelle durch Schnitte in $\theta^{2}$ grundsätzlich schlechter werden, wird ein Modell trainiert, bei dessen Trainingsdatensatz die Proton-Simulationen in verschiedenen $\theta^{2}$ geschnitten werden. 
Die Signifikanz für die Detektion des Krebsnebels der unterschiedlich trainierten Modelle ist in Abbildung \ref{fig:corrtheta} dargestellt.
\begin{figure}[H]
  \centering
  \includegraphics[scale=1]{Plots/corr_sig_theta2.pdf}
  \caption{Signifikanz in Abhängigkeit des $\theta^{2}$-Schnitts auf dem Trainingsdatensatz der simulierten Protonen.}
  \label{fig:corrtheta}
\end{figure}
Bei Schnitten auf den Monte Carlo-Protonen bis $\theta^{2} < 1$ hängt die Signifikanz nicht von $\theta^{2}$ ab.
Bei Werten $\theta^{2} > 1$ nimmt die Signifikanz ab, weil Detekoreigenschaften im Training vernachlässigt werden.

Es scheinen $\theta^{2}$-Schnitte zwischen \num{0.5} bis \num{1} plausibel. 
Für Monte Carlo basierte Modelle nimmt die Signifikanz der Quelle nicht ab, wenn Protonen mit $\theta^{2} < \num{1}$ aus dem Trainingsdatensatz entfernt werden. 
Des weiteren ist das Verhältniss an Gamma-Ereignissen $\theta^{2} > \num{0.5}$ im Untergrunddatensatz gering, sodass diese als diffuse Gamma-Ereignisse angesehen werden können. 
Für die weitere Analyse wurde fortlaufend ein $\theta^{2}$-Schnitt von \num{0.5} gewählt. 
\newpage
\section{Optimierung der Modelle}
Um zu evaluieren, welche Methode besser zwischen den elektromagnetischen und hadronischen Schauern separiert, werden zwei Datensätze erstellt. 
\begin{enumerate}
  \item \textbf{MC-Daten:} Monte Carlo Gamma + Monte Carlo Protonen
  \item \textbf{Messdaten:} Monte Carlo Gamma + gemessene Protonen 
\end{enumerate}
Dabei wird auf den simulierten Protonen kein $\theta^{2}$-Schnitt durchgeführt, weil dieser frei von Gamma-Ereignissen ist.
Mit den erstellten Trainings-Datensätzen wird ein Klassifizierer trainiert und der ROC-AUC-Wert für diesen bestimmt.
Bei einem \texttt{Random Forest} ist die Anzahl an Bäumen (\texttt{n\_estimators}), die Tiefe der Bäume (\texttt{max\_depth}) und die Anzahl an Trainingsattributen (\texttt{max\_feature}) variabel, sodass sich hier Möglichkeiten der Beschränkung bieten.

Für die Analyse wird die Anzahl der Bäume beim \texttt{Random Forest} auf \texttt{n\_estimators = 100} konstant gehalten. 
Mithilfe eines Parameternetzes wird die optimale Konstellation der Parameter gesucht. 
\begin{figure}
  \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{Plots/parameter_monte.pdf}
	\caption{Monte Carlo-Daten}
	\label{fig:mcGrid}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{Plots/parameter_crab.pdf}
	\caption{Messdaten}
	\label{fig:messGrid}
  \end{subfigure}
  \caption{Parameternetz zum Ermitteln der optimalen Parameter auf den unterschiedlichen Datensätzen.}
\end{figure}

Es fällt auf, dass sich die beiden Datensätze unterschiedlich gut trennen lassen.
Beide Modelle weisen dabei die selben Parameter auf, bei denen der ROC-AUC-Wert maximal wird.
Des weiteren ist der maximale ROC-AUC-Wert bei dem auf Messdaten trainierten Lerner etwas größer als bei dem auf Monte Carlo-Daten trainierten Lerner.
Dies entspricht einem Modell, welches besser das Signal vom Untergrund separiert.
\begin{table}[H]
  \centering
  \caption{ROC-AUC-Wert in Abhängigkeit der Trainingsdatensätze.}
  \begin{tabular}{l s s}
	\toprule
	& MC-Daten & Messdaten \\
	\cmidrule(r){2-3}
	\texttt{XGBoost Classifier}	(Tiefe 1)	& \num{0.86(2)}	&\num{0.869(5)} \\ 
	\texttt{Random Forrest}					& \num{0.87(1)} & \num{0.89(1)} \\
	\bottomrule
  \end{tabular}
  \label{tab:ROC-AUC}
\end{table}
Die Bäume der Tiefe eins brauchen nicht optimiert zu werden, da sie aufgrund der stark begrenzten Tiefe nicht an Übertraining leiden.
Aufgrund ihrer starken Bregrenzung sind die ROC-AUC-Wert erwartungsgemäß niedriger als beim \texttt{Random Forest}.
\section{Signifikanz der Modelle}
Um ein Maß für die Güte der Modelle zu erhalten, wird die Signifikanz zweier unabhängiger Quellen bestimmt. 
Dafür werden die Klassifizierer einmal mit dem MC-Daten und einmal mit den Messdaten trainiert. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./tikz/conf/conf.pdf}
  \caption{Schaubild zur Bestimmung der Signifikanz für die Detektion einer Quelle.}
\end{figure}
Im Anschluss wird für jedes Ereignis ein Konfidenzwert bestimmt. 
Der Konfidenzwert spiegelt die Sicherheit des Klassifizierers wider, dass das Ereignis ein Gamma- \texttt{1} oder ein Proton-Schauer \texttt{0} ist. 
In Abbildung~\ref{fig:confdist} ist die Konfidenzverteilung des klassifizierten Krebsnebel-Datensatzes aufgetragen. 
Auffällig ist, dass ein Großteil der Ereignisse eindeutig der Klasse Proton zugeordnet werden kann. 
Im Gegensatz dazu finden sich keine Ereignisse, die sich eindeutig der Klasse Gamma zuordnen lassen.
\begin{figure}[H]
  \centering
  \includegraphics[scale=1]{./Plots/conf.pdf}
  \caption{Konfidenzverteilung der Krebsnebel-Daten, erstellt mit einem \texttt{Random Forest}, welcher einmal mit simulierten Protonen und einmal mit gemessenen trainiert wurde.}
  \label{fig:confdist}
\end{figure}
Dies liegt vermutlich dem physikalischen Problem zugrunde, dass ein Proton, welches beim Eintritt in die Atmosphäre schon früh in ein $\pi^{0}$ Meson und ein $e^{+}$ zerfällt, kaum von einem elektromagnetischen Schauer zu unterscheiden ist (siehe Kapitel \ref{sec:cherenkov}).

Zur Bestimmung der maximalen Signifikanz der Quelle wird ein Schnitt in $\theta^{2}$ angewendet, sodass das Verhältnis von On- zu Off-Daten möglichst groß ist.
Dabei wird die Menge unterhalb des Schnittes als Gamma- und oberhalb als Proton-Ereignisse klassifiziert.
Die klassifizierten Gamma-Ereignisse setzen sich dementsprechend aus richtig klassifizierten Gamma- (TP) und falsch klassifizierten Proton-Ereignissen (FP) zusammen. 
Die Größe der Signifikanz wird durch das Verhältnis von TP zu FP bestimmt.
\begin{figure}[H]
  \centering
  \includegraphics[scale=1]{./Plots/on_off_ratio.pdf}
  \caption{Signifikanz des Krebsnebels auf den unklassifizierten Datensatz.}
  \label{fig:sig_crab}
\end{figure}
Ein grafisches Beispiel für die Signifikanz ist in Abbildung~\ref{fig:sig_crab} zu sehen. 
Abgebildet ist die $\theta^{2}$-Verteilung der On-Position und das Mittel der fünf Off-Positionen.
Dabei ist die Signifikanz des unklassifizierten Krebsnebel-Datensatzes dargestellt, welcher bereits ohne Separation mit einer Signifikanz von \SI{21,4}{\sigma} nachgewiesen werden kann.
% Dabei wurde ein Konfidenzschnitt von 0 durchgeführt, was die Signifikanz des Rohdaten entspricht. Die verwedete Quelle ist der Krebsnebel welche bereits ohne Klassifizierung eine Siknifikanz der Daten in einem Bereich von $\theta^{2} < 0.03$ beträgt \SI{21,4}{\sigma}.

Durch die Bereinigung des Datensatzes wird versucht die Signifikanz zu erhöhen.
Dafür wird sowohl ein \texttt{Random Forest} benutzt, als auch ein \texttt{XGBoost Classifier} der Tiefe eins. 
Der \texttt{XGBoost Classifier} hat den Vorteil, dass er aufgrund des additiven Trainings noch einen Erkenntnisgewinn aus der Fehlklassifizierung zieht.
Somit kann er durch die Umgewichtung der Ereignisse mit der gleichen Anzahl an Attributen mehr unterschiedliche Bäume als der \texttt{Random Forest} bauen.

Die Signifikanz des Krebsnebel- und Markarian-501-Datensatzes werden jeweils auf der kompletten Größe der Datensätze bei $\theta^{2} < \num{0.03}$ bestimmt. 
Beide Modelle werden mit jeweils einer Trainingsgröße von \num{100000} Ereignissen aus Gamma- und Proton-Ereignissen gleichermaßen trainiert. 
\begin{table}[H]
  \centering
  \caption{Signifikanzen der Quellen Krebsnebel und Markarian 501, ermittelt durch einen \texttt{Random Forest} sowie \texttt{XGBoost Classifier}. Diese wurden jeweils mit einem Datensatz aus simulierten bzw. gemessenen Untergrund-Ereignissen trainiert. Des weiteren ist die Signifikanz der unklassifizierten Datensätze aufgetragen.}
  \begin{tabular}{l s s s s}
	\toprule
	& \multicolumn{2}{c}{Krebsnebel}	& \multicolumn{2}{c}{Markarian 501} \\
	  \cmidrule(r){2-3} \cmidrule(l){4-5}
	  & Random & XGBoost 		& Random & XGBoost 	 \\
	& Forest & (Tiefe= 1) 	& Forest & (Tiefe= 1)\\
	unklassifizierte Daten & \multicolumn{2}{c}{\SI{21.4}{\sigma}}	& \multicolumn{2}{c}{\SI{17.1}{\sigma}} \\
	MC-Proton	 		   & \SI{41.9}{\sigma}	& \SI{41.3}{\sigma}	& \SI{35.5}{\sigma}	& \SI{35.6}{\sigma}\\
	gemessene Proton	   & \SI{32.9}{\sigma}	& \SI{37.8}{\sigma}	& \SI{23.6}{\sigma}	& \SI{35.2}{\sigma}\\
	\bottomrule
  \end{tabular}
  \label{tab:sign}
\end{table}
Die Signifikanz der beiden Quellen ist in Tabelle \ref{tab:sign} niedergeschrieben. 
Auffällig ist, dass im Gegensatz zum ROC-AUC-Wert die Signifikanz des mit den gemessenen Daten trainierten Klassifizierers geringer ist, als die des Klassifizierers, der mit Monte Carlo-Daten trainiert wurde.
Zu erwarten wäre gewesen, dass der Klassifizierer, welcher besser separiert, auch eine höhere Signifikanz liefert. 

Bei dem \texttt{XGBoost Classifier} tritt dieser Effekt wesentlich schwächer als beim \texttt{Random Forest} auf. 
Dies deutet auf Übertraining oder eine schlechte Übereinstimmung zwischen gemessenen Daten und der Monte Carlo-Simulation hin.
Möglicherweise wird der Klassifizierer nicht mehr darauf trainiert, zwischen Gamma- und Proton-Ereignissen zu unterscheiden, sondern gemessene von Monte Carlo Ereignissen zu separieren.

\section{Konfidenzwert}
\label{sec:konf}
In Abbildung~\ref{fig:signconf} ist die Signifikanz für die einzelnen Konfidenzwerte des Krebsnebel-Datensatzes dargestellt. 
Anhand der Form können Rückschlüsse über die Klassifizierer gezogen werden. 

Der Erwartung entsprechend streben die Signifikanzen für sehr kleine Konfidenz-Werte gegen die des unklassifizierten Datensatz und bei großen gegen null.

Dazwischen werden alle Modelle maximal und eignen sich dafür, die Signifikanz der Quelldaten zu vergrößern.
Die Signifikanz steigt in allen Fällen für größer werdende Konfidenzen stetig an und erreicht zwischen \num{0.7} und \num{0.9} ein Maximum.
Aufgrund des stetigen Anstieges ist davon auszugehen, dass es sich beim Maximum der Verteilung nicht um statistisches Rauschen handelt.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./Plots/sig_mess_tree.pdf}
  \caption{\texttt{Random Forest}}
  \label{fig:signconfMC}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./Plots/sig_mess_xgbc.pdf}
  \caption{\texttt{XGBoost Classifier} (Tiefe 1)}
  \label{fig:signconfMESS}
\end{subfigure}
\caption{Signifikanz der Modelle in Abhängigkeit der verschiedenen Konfidenz-Schnitte für die mit MC-Daten sowie Messdaten trainierten Klassifizierer.}
\label{fig:signconf}
\end{figure}
Auffällig ist, dass sich die Konfidenzverteilungen trotz der verschiedenen Klassifizierer für die Monte Carlo-Daten ähneln.
Beim stark in der Tiefe beschränkten \texttt{XGBoost Classifier} werden die Signifikanzen annähernd im selben Bereich maximal, wohingegen beim \texttt{Random Forest} die maximalen Signifikanzen des anhand von Messdaten trainierten Modells einer anderen Verteilung folgen und schon früher maximal werden. 
Eine Ursache dafür ist (Abbildung~\ref{fig:confdist}), dass die Anzahl an mit hohen Konfidenzwerten (\num{> 0.8}) klassifizierten Ereignissen gering ist. 
Ein \texttt{Random Forest}, der auf gemessenen Daten trainiert wurde, ist sich also bei der Klassifizierung von Ereignissen wesentlich unsicherer, ob es sich um ein Gamma- oder Proton-Ereignis handelt.
Ein Grund dafür können Daten-Monte Carlo-Mismatches sein. 
Der Lerner sieht im Training verstärkt die Unterschiede zwischen Simulation und Wirklichkeit, statt zwischen Gamma- und Hadron-Ereignissen.
Da die Abweichungen im zu klassifizierenden Datensatz nicht mehr vorhanden sind, wird die Prognose des Lerners unsicher.
Dass dieser Effekt beim \texttt{Random Forest} stärker auftritt, könnte daran liegen, dass hier öfter Attribute mit höherem Daten-Monte Carlo-Mismatch zum Aufbau des Baumes gewählt werden als beim \texttt{XGBoost Classifier} der Tiefe eins.
\newpage
\section{Rekursive Attribut Eliminierung}
Da die Modelle, wie in Kapitel \ref{sec:konf} beschrieben, bei der Separation lernen, zwischen gemessenen und simulierten Daten zu unterscheiden, liegt die Vermutung nahe, dass einige Attribute schlecht simuliert sind.
Durch das Entfernen der schlecht simulierten Attribute soll dieser Effekt reduziert werden.

Dazu wird zunächst ein Modell trainiert, welches aus gleich vielen Teilen an simulierten und gemessenen (nach Kapitel \ref{sec:makeUnter} zusammengestellten) Proton-Ereignissen besteht. 
Im Falle, dass das Modell die simulierten nicht von den gemessenen Protonen unterscheiden kann, wird der ROC-AUC-Wert ungefähr \num{0.5} betragen. 
Der ROC-AUC-Wert beträgt auf dem Testdatensatz \num{0.64}, was die Vermutung bestätigt, dass die Simulation nicht optimal der Wirklichkeit angepasst ist. 

Zur Visualisierung der Attribute, bei denen sich die gemessenen von simulierten Daten unterscheiden, sind die Gewichte (feature importances) der Attribute im \texttt{Random Forest} in Abbildung~\ref{fig:featureimportance} dargestellt. 
\begin{figure}[H]
  \centering
  \includegraphics[scale=1]{./Plots/feature_elemination.pdf}
  \caption{Gewichte der Attribute des Random Forest zur Separation von gemessenen und simulierten Daten, sowie der Gamma/Hadron-Separation.}
  \label{fig:featureimportance}
\end{figure}
Beim Entfernen eines Attributes wird auch Informationsgehalt verworfen. 
Dementsprechend muss ein Verhältnis zwischen schlecht simulierten Monte Carlo-Attributen einerseits und Informationsgehalt anderseits gefunden werden.
\begin{table}
  \centering
  \caption{Auswirkung der Attribut Eliminierung auf den ROC-AUC-Wert sowie die Li und Ma Signifikanz.}
  \begin{tabular}{l s s}
	\toprule
								& ohne Attribut & mit Attribut \\
								& Eliminierung 	& Eliminierung \\
	  	\cmidrule(r){2-3} 
	  	ROC-AUC-Wert 			& \num{0.64} & \num{0.61} \\
		Li und Ma Signifikanz 	& \SI{32.9}{\sigma} & \SI{34.4}{\sigma} \\
	\bottomrule
  \end{tabular}
  \label{tab:<+label+>}
\end{table}
Durch das Entfernen der Attribute \texttt{ph\_charge\_shower\_max}, \texttt{concentration\_two\_pixel}, \texttt{leakage2} und \texttt{width} lässt sich sowohl der ROC-AUC-Wert der Separation zwischen simulierten und echten Daten minimieren, als auch die Signifikanz des auf echten Daten trainierten \text{Random Forest} um circa ein $\sigma$ erhöhen.
