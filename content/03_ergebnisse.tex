\chapter{Gamma/Hadron-Separation mit gemessenen Daten}
Ziel der Gamma/Hadron-Separation ist es, die von einem Cherenkov-Teleskop gemessenen Ereignisse den beiden Klassen Signal (Gamma) und Untergrund (Proton) zuzuordnen.
Mit den klassifizierten Gamma-Ereignissen kann dann zum Beispiel der Fluss einer Quelle im Bereich der Gammastrahlung berechnet werden.

Für die Separation zwischen elektromagnetischen und hadronischen Schauern muss ein Modell anhand eines klassifizierten Datensatzes trainiert werden.
Dazu wird zunächst mit der Software \texttt{FACT-Tools} \cite{Christian Bockermann} ein klassifizierter Datensatz prozessiert.
%Ziel der Arbeit ist es die Monte-Carlo simulierten Protonen durch gemessene zu ersetzen.
Ziel der Arbeit ist zu untersuchen, ob die Gamma/Hadron-Separation durch die Verwendung von gemessenen statt simulierten Untergrunddaten im Trainingsdatensatz verbessert werden kann.

Es ist bekannt, dass die Verteilung der Attribute auf simulierten und gemessenen Daten unterschiedlich aussehen.
Dieses Problem wird Daten-Monte Carlo-Mismatch genannt.
Durch die Verwendung des gemessenen Untergrunds anstelle der simulierten Protonen soll der Mismatch minimiert und die Klassifikation verbessert werden.
%Da gemessene Protonen besser als simulierte den Untergrund wiedergeben, besteht die Idee, die Klassifikation dadurch zu optimieren.
Bei ähnlichen Experimenten, wie z.B. MAGIC, hat sich diese Methode bereits bewährt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./tikz/motiv/motiv.pdf}
  \caption{Analysekette zur Evaluation der Trainingsmethoden.}
\end{figure}
Zur Überprüfung dieser Methode werden ein \texttt{Random Forest}, so wie ein \texttt{XGBoost Classifier} der Tiefe 1 trainiert und optimiert.
Aus dem Verhältnis der Signifikanzen der beiden Klassifizierer, lässt sich womöglich Aufschluss über die Klassifikation erhalten.

Das Trennvermögen der auf den beiden unterschiedlichen Datensätzen trainierten Modelle wird anhand der Receiver Operating Curve gemessen.

Desweiteren wird die Signifikanz von zwei verschiedenen Quellen berechnet, die durch zwei unterschiedlich trainierte Modelle gefunden werden. 
Anhand der maximalen Signifikanzen werden die Modelle verglichen.
\section{Erstellen des gemessenen Untergrund}
\label{sec:makeUnter}
Aufgrund der geringen Spiegelfläche und der damit verbundenen geringen Auflösung betreibt FACT hauptsächlich Langzeitstudien von bekannten hellen Quellen und alarmiert andere Experimente bei ungewöhnlich hohen Flussraten.
Um die Observationszeit zu maximieren, nimmt FACT dafür Daten im Wobble Modus auf. 
Dabei muss die Kamera nicht extra auf Off-Positionen gerichtet werden und kann dementsprechend effizienter in der selben Zeit arbeiten. 
Dies hat zur Folge, dass keine gemessenen Untergrund/Hadron-Daten existieren. 

Für die Erstellung eines alternativen Protonendatensatzes müssen aus dem Datensatz einer Quelleobservation die Protonenereignisse heraussepariert werden. 
Dies wird mit einem Schnitt in $\theta^{2}$ realisiert/
Denkbar wäre auch, einem maschinellen Lerner die Filterung auf Protonen zu überlassen.
Allerdings würden hier die Monte Carlo-Mismatches erneut eingehen. 
Aus diesem Grund kann darauf verzichtet werden.

Dementsprechend wird anhand des trennstärksten Attributs $\theta^{2}$ versucht, eine Separation von Daten einer Quelle in Protonen und Gammas durchzuführen. 
Die Trennstärke des trennstärksten Parameters $\theta^{2}$ im Vergleich zu allen anderen verfügbaren Parametern ist in Abbildung~\ref{fig:roc} dargestellt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Plots/theta_cut.pdf}
  \caption{$\theta^{2}$ Verteilung von simulierten Gamma- und Protonen-Ereignissen, sowie das Verhältnis von Gamma- zu Protonen-Events.}
  \label{fig:thetacut}
\end{figure}
Durch einen Schnitt auf der $\theta^{2}$-Verteilung soll ein möglichst reiner Datensatz erstellt werden. 
In Abbildung~\ref{fig:thetacut} sind für Hadronen und Protonen die $\theta^{2}$-Verteilungen der Monte Carlo-Simulationen aufgetragen. 
Für kleine $\theta^{2}$-Werte ist das Gamma Signal um vielfaches größer und nimmt für größer werdende $\theta^{2}$-Werte kontinuierlich ab. 
Ab einem $\theta^{2}$-Wert von $0.5$ ist das Signal- zu Hintergrundverhältnis um ein Zehntel kleiner.
Da der wahre Untergrund sowohl aus Hadronen als auch aus wenigen diffusen Gammaquanten besteht, ist zu erwarten, dass die vereinzelt verbleibenden Gamma-Ereignisse die Klassifizierer nicht weiter negativ beeinflussen.

% Zu beachten ist das Protonen zwar isotrop verteilt seien sollten, jedoch bei zu großen $\theta^{2}$-cuts die Detektoreigenschaften singnifikant werden. Um zu überprüfen inwiefern die Detektoreigenschaften vernachlässigt werden können ist in Abbildung~\ref{fig:corrtheta} die Signifikanz in Abhängigkeit des Parameters $\theta^{2}$ dargestellt.
Um zu überprüfen, ob die trainierten Modelle durch Schnitte in $\theta^{2}$ grundsätzlich schlechter werden, wird ein Modell trainiert, bei dessen Trainingsdatensatz die Proton-Simulationen in verschiedenen $\theta^{2}$ geschnitten werden. 
Die Signifikanz der unterschiedlich trainierten Modelle ist in Abbildung \ref{fig:corrtheta} dargestellt.
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Plots/corr_sig_theta2.pdf}
  \caption{Signifikanz in Abhängigkeit des $\theta^{2}$-Schnitts auf dem Trainingsdatensatz der simulierten Protonen.}
  \label{fig:corrtheta}
\end{figure}
Bei Schnitten auf den Monte Carlo-Protonen bis $\theta^{2} < 1$ hängt die Signifikanz nicht von $\theta^{2}$ ab.
Bei Werten $\theta^{2} > 1$ nimmt die Signifikanz ab, weil Detekoreigenschaften im Training vernachlässigt werden.

Es scheinen $\theta^{2}$-Schnitte zwischen \num{0.5} bis \num{1} plausibel. 
Für Monte Carlo basierte Modelle nimmt die Signifikanz der Quelle nicht ab, wenn Protonen mit $\theta^{2} < \num{1}$ aus dem Trainingsdatensatz entfernt werden. 
Desweiteren ist das Verhältniss an Gamma-Ereignissen $\theta^{2} > \num{0.5}$ im Untergrunddatensatz gering, sodass diese als diffuse Gamma Ereignisse angesehen werden können. 
Für die weitere Analyse wurde fortlaufend ein $\theta^{2}$-Schnitt von \num{0.5} gewählt. 
\newpage
\section{Optimierung der Modelle}
Um zu evaluieren, welche Methode besser zwischen den elektromagnetischen und hadronischen Schauern separiert, werden zwei Datensätze erstellt. 
\begin{enumerate}
  \item \textbf{MC-Daten:} Monte Carlo Gamma + Monte Carlo Protonen
  \item \textbf{Messdaten:} Monte Carlo Gamma + gemessene Protonen 
\end{enumerate}
Dabei wird auf den simulierten Protonen kein $\theta^{2}$-Schnitt durchgeführt, weil dieser frei von Gamma-Ereignissen ist.
Mit den erstellten Trainings-Datensätzen wird ein Klassifizierer trainiert und der AUC-Wert für diesen bestimmt.
Bei einem Random Forest ist die Anzahl an Bäumen (\texttt{n\_estimators}), die Tiefe der Bäume (\texttt{max\_depth}) und die Anzahl an Trainingsattributen (\texttt{max\_feature}) variable, sodass sich hier Möglichkeiten der Beschränkung bieten.

Für die Analyse wird die Anzahl der Bäume beim Random Forest auf \texttt{n\_estimators = 100} konstant gehalten. 
Mithilfe eines Parameternetzes wird die optimale Konstellation der Parameter gesucht. 
\begin{figure}
  \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{Plots/parameter_monte.pdf}
	\caption{Monte Carlo-Daten}
	\label{fig:mcGrid}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{Plots/parameter_crab.pdf}
	\caption{Messdaten}
	\label{fig:messGrid}
  \end{subfigure}
  \caption{Parameternetz zum Ermitteln der optimalen Parameter auf den unterschiedlichen Datensätzen.}
\end{figure}

Dabei fällt auf, dass sich die beiden Datensätze unterschiedlich gut trennen lassen.
Beide Modelle weisen dabei dieselbem Parameter auf, bei denen der AUC-Wert maximal wird.
Desweiteren ist der maximale AUC-Wert bei dem auf Messdaten trainierten Lerner größer als bei dem auf Monte Carlo-Daten trainierten Lerner.
Dies entspricht einem Modell welches besser Signal von Untergrund separiert.

Die Bäume der Tiefe eins brauchen nicht optimiert zu werden, da sie aufgrund der stark begrenzten Tiefe nicht an Übertraining leiden.

\section{Signifikanz der Modelle}
Um ein Maß für die Güte der Modelle zu erhalten, wird die Signifikanz zweier unabhängiger Quellen bestimmt. 
Dafür werden die Klassifizierer einmal mit dem MC-Daten und einmal mit den Messdaten trainiert. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./tikz/conf/conf.pdf}
  \caption{Schaubild zur Bestimmung der Signifikanz einer Quelle}
  \label{fig:<+label+>}
\end{figure}
Im Anschluss wird für jedes Ereignis ein Konfidenzwert bestimmt. 
Der Konfidenzwert spiegelt die Sicherheit des Klassifizierers wieder, dass das Ereignis ein Gamma- \texttt{1} oder ein Proton-Schauer \texttt{0} ist. 
In Abbildung~\ref{fig:confdist} ist die Konfidenzverteilung des klassifizierten Krebsnebel-Datensatzes aufgetragen. 
Dabei ist auffällig, dass ein Großteil der Ereignisse eindeutig der Klasse Proton zugeordnet werden kann. 
Im Gegensatz dazu, finden sich keine Ereignisse, die sich eindeutig der Klasse Gamma zuordnen lassen.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{./Plots/conf.pdf}
  \caption{Konfidenzverteilung der Krebsnebel-Daten, erstellt mit einem \texttt{Random Forest} welcher einmal anhand von simulierten Protonen und einmal auf gemessenen trainiert wurde.}
  \label{fig:confdist}
\end{figure}
Dies liegt dem physikalischem Problem zugrunde, dass ein Proton, welches beim Eintritt in die Atmosphäre schon früh in ein $\pi^{0}$ Meson und einem $e^{+}$ zerfällt und kaum von einem elektromagnetischen Schauer zu unterscheiden ist (siehe Kapitel \ref{sec:cherenkov}).

Zur Bestimmung der maximalen Signifikanz der Quelle wird ein Schnitt in $\theta^{2}$ angewendet, sodass das Verhältnis von On- zu Off-Daten möglichst groß ist.
Dabei wird die Menge unterhalb des Schnittes als Gamma- und oberhalb als Proton-Ereignisse klassifiziert.
Die klassifizierten Gamma-Ereignisse setzen sich dementsprechend aus richtig klassifizierten Gamma- (TP) und falsch klassifizierten Proton-Ereignissen (FP) zusammen. 
Die Größe der Signifikanz wird durch das Verhältnis von TP zu FP bestimmt.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.88\textwidth]{./Plots/on_off_ratio.pdf}
  \caption{Signifikanz von Crab auf den unklassifizierten Datensatz}
  \label{fig:sig_crab}
\end{figure}
Ein grafisches Beispiel für die Signifikanz ist in Abbildung~\ref{fig:sig_crab} zu sehen. 
Abgebildet ist die $\theta^{2}$-Verteilung der On-Position und das Mittel der fünf Off-Positionen.
Dabei ist die Signifikanz des unklassifizierten Krebsnebel Datensatzes dargestellt, welcher bereits ohne Separation mit einer Signifikanz von \SI{21,4}{\sigma} nachgewiesen werden kann.
% Dabei wurde ein Konfidenzschnitt von 0 durchgeführt, was die Signifikanz des Rohdaten entspricht. Die verwedete Quelle ist der Krebsnebel welche bereits ohne Klassifizierung eine Siknifikanz der Daten in einem Bereich von $\theta^{2} < 0.03$ beträgt \SI{21,4}{\sigma}.

Durch die Bereinigung des Datensatzes wird versucht die Signifikanz zu erhöhen.
Dafür wird einerseits ein \texttt{Random Forest} benutzt, als auch ein \texttt{XGBoost Classifier} der Tiefe 1. 
Dabei hat der \texttt{XGBoost Classifier} den Vorteil, dass er aufgrund des additiven Trainings noch einen Erkenntnisgewinn aus der Fehlklassifizierung zieht, nachdem die Anzahl an allen möglichen Attribute an Bäumen gezogen wurden.

Die Signifikanzen des Krebsnebel und Markarian-501 Datensatzes werden jeweils auf der kompletten Größe der Datensätze bei $\theta^{2} < \num{0.03}$ bestimmt. 
Beide Modelle werden mit jeweils einer Trainings Größe von \num{100000} Ereignissen aus Gamma- und Proton-Ereignissen gleichermaßen trainiert. 
\begin{table}[H]
  \centering
  \caption{Signifikanzen der Quellen Krebsnebel und Markarian 501, ermittelt durch einen \texttt{Random Forest} sowie \texttt{XGBoost Classifier}. Diese wurden jeweils mit einem Datensatz aus simulierten bzw. gemessenen Untergrund Ereignissen trainiert. Desweiteren ist die Signifikanz der unklassifizierten Datensatzes aufgetragen.}
  \begin{tabular}{l s s s s}
	\toprule
	& \multicolumn{2}{c}{Krebsnebel}	& \multicolumn{2}{c}{Markarian 501} \\
	  \cmidrule(r){2-3} \cmidrule(l){4-5}
	  & Random & XGBoost 		& Random & XGBoost 	 \\
	& Forest & (Tiefe= 1) 	& Forest & (Tiefe= 1)\\
	unklassifizierte Daten & \multicolumn{2}{c}{\SI{21.4}{\sigma}}	& \multicolumn{2}{c}{\SI{17.1}{\sigma}} \\
	MC-Proton	 		   & \SI{41.9}{\sigma}	& \SI{41.3}{\sigma}	& \SI{35.5}{\sigma}	& \SI{35.6}{\sigma}\\
	gemessene Proton	   & \SI{32.9}{\sigma}	& \SI{37.8}{\sigma}	& \SI{23.6}{\sigma}	& \SI{35.2}{\sigma}\\
	\bottomrule
  \end{tabular}
  \label{tab:sign}
\end{table}
Die Signifikanz der beiden Quellen ist in Tabelle \ref{tab:sign} niedergeschrieben. 
Auffällig ist, dass im Gegensatz zum AUC-Wert die Signifikanz des mit den gemessenen Daten trainierten Klassifizierers geringer ist, als die des Klassifizierers, der mit Monte Carlo Daten trainiert wurde.
Zu erwarten wäre gewesen, dass der Klassifizierer, welcher besser separiert, auch eine höhere Signifikanz hat. 

Bei dem \texttt{XGBoost Classifier} tritt dieser Effekt wesentlich schwächer als beim \texttt{Random Forest} auf. Dies deutet auf Übertraining des \texttt{Random Forest} hin. 
Möglicherweise wird der Klassifizierer nicht mehr darauf trainiert, zwischen Gamma- und Proton-Ereignissen zu unterscheiden, sondern gemessene von Monte Carlo Ereignissen zu separieren.

\section{Konfidenzwert}
In Abbildung \ref{fig:signconf} ist die Signifikanz für die einzelnen Konfidenzwerte dargestellt. 
Anhand der Form können Rückschlüsse über die Klassifizierer gezogen werden. 

Bei kleinen Konfidenzwerten strebt die Signifikanz gegen die des unklassifizierten Datensatzes.
Aufgrund der Größe der als Gamma klassifizierten Ereignisse strebt die Signifikanz für große Konfidenzwerte gegen 0.
Dazwischen ist die Signifikanz ein Maß für die Größe der Probe in Abhängigkeit der als richtig klassifizierten Gamma-Ereignisse.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./Plots/sig_mess_tree.pdf}
  \caption{\texttt{Random Forest}}
  \label{fig:signconfMC}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./Plots/sig_mess_xgbc.pdf}
  \caption{\texttt{XGBoost Classifier}}
  \label{fig:signconfMESS}
\end{subfigure}
\caption{Signifikanz der Modelle in Abhängigkeit der verschiedenen Confidence Werte für die mit Mc-Daten sowie Mess-Daten trainierten Klassifizierer}
\label{fig:signconf}
\end{figure}

Auffällig ist, dass sich die Konfidenzverteilungen trotz der verschiedenen Klassifizierer für die Monte Carlo-Daten ähneln.
Dabei scheint der \texttt{Random Forest} ein Problem mit Ereignissen, die hohe Konfidenzwerte aufweisen, zu haben. 
Möglicherweise konnte er beim Training in diesem Bereich durch die Separation von Monte Carlo  und gemessenen Daten eine große Trennstärke erreichen. 
Da diese Information bei gemessen Daten nicht eingeht, hat der Lerner somit Probleme bei hohen Konfidenzwerten.

Der \texttt{XGBoost Classifier} scheint aufgrund seiner beschränkten Tiefe von diesem Problem weniger betroffen. 

\section{Rekusive Feature Elemination}
Da Modelle bei der Separation lernen, zwischen gemessenen und simulierten Daten zu unterscheiden, liegt die Vermutung nahe, dass einige Attribute schlecht simuliert sind.
Durch das Entfernen von den schlecht simulierten Attributen, soll die Klassifikation zwischen simulierten und gemessen Daten reduziert werden.

Dazu wird zunächst ein Modell trainiert, welches aus gleich vielen Teilen an simulierten und gemessenen (nach Kapitel \ref{sec:makeUnter} zusammengestellt) Proton-Ereignissen besteht. 
Im Falle, dass das Modell die simulierten nicht von den gemessenen Protonen unterscheiden kann, wird der AUC-Wert ungefähr \num{0.5} betragen. 
Der AUC-Wert beträgt auf dem Testdatensatz \num{0.64}. 

Zur Visualisierung der Attribute bei denen sich die gemessenen von simulierten Daten unterscheiden, sind die Gewichte des trainierten Modells ist in Abbildung~\ref{fig:featureimportance} dargestellt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./Plots/feature_elemination.pdf}
  \caption{Gewichte der Attribute des Random Forest zur Separation von gemessenen und simulierten Daten, sowie der Gamma/Hadron-Separation }
  \label{fig:featureimportance}
\end{figure}
Bei dem Entfernen eines Attributes wird Informationsgehalt verworfen. 
Dementsprechend muss ein Verhältnis zwischen schlecht simulierten Monte Carlo-Attributen einerseits und Informationsgehalt anderseits gefunden werden.

Durch das Entfernen der Attribute \texttt{ph\_charge\_shower\_max}, \texttt{width}, \texttt{leakage2} und \texttt{concentration\_two\_pixel} lässt sich sowohl der AUC-Wert der Separation zwischen simulierten und echten Daten minimieren, als auch die Signifikanz des auf echten Daten trainierten Random Forest um circa \SI{1}{\sigma} erhöhen.
