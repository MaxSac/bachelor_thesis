\chapter{Gamma Hadron Seperation mit gemessenen Daten}
Für die Separation zwischen Gamma und Hadronen muss ein Modell anhand eines klassifizierten Datensatzes trainiert werden.
%Dabei wurde bis jetzt anhand der FACT-Tools \cite{FACT-Tools}, der klassifizierte Datensatz aus Monte Carlo simulierten Gammas so wie Protonen erstellt. 
Dazu wird zunächst mit der Software ``FACT-Tools'' ein klassifizierter MonteCarlo simulierter Datensatz prozessiert.
%Ziel der Arbeit ist es die Monte-Carlo simulierten Protonen durch gemessene zu ersetzen.
\textbf{Ziel der Arbeit ist zu überprüfen ob, durch den Ersatz von Monte-Carlo simulierten durch gemessene Protonen im Trainingdatensatz der Klassifizierer, die Gamma/Hadron Separation zu verbessern ist.}
Da gemessene Protonen besser als simulierte den Untergrund wiedergeben, besteht die Idee, die Klassifikation dadurch zu optimieren.
Bei ähnlichen Experimenten, wie z.B. MAGIC, hat sich diese Methode bereits bewährt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./tikz/motiv/motiv.pdf}
  \caption{Analysekette zur Bewertung welcher Trainingsdatensatz besser für die Gamma Hadron seperation geeignet ist.}
\end{figure}
Zur Überprüfung dieser Methode werden ein \texttt{Random Forest}, so wie ein \texttt{XGBOOST Classifier} der Tiefe 1 trainiert und optimiert.
Aus dem Verhältniss, der Signifikanzen der beiden Klassifizierer, lässt sich womöglich Aufschluss über die Klassifikation erhalten.

Das Trennvermögen der auf den beiden unterschiedlichen Datensets trainierten Modelle wird anhand der Receiver Operating Curve gemessen.

Desweiteren wird die Signifikanz von zwei verschiedenen Quellen verechnet, die durch zwei unterschiedlich trainierte Modelle gefunden werden. 
Dabei werden hauptsächlich die maximalen Signifikanzen der Klassifizierer verglichen.
\section{Erstellen des gemessenen Untergrund}
Aufgrund der geringen Spiegelfläche und der damit verbudenen geringen Auflösung betreibt FACT hauptsächlich Langzeitstudien von bekannten hellen Quellen und alarmiert andere Experimente bei ungewöhnlich hohen Flussraten.
Um die Observationszeit zu maximieren, nimmt FACT dafür Daten im Wobble Modus auf. 
Dabei muss die Kamera nicht extra auf Off-Positionen gerichtet werden und kann dementsprechend effizienter in der selben Zeit arbeiten. 
Dies hat zur Folge, dass keine expliziten gemessenen Untergrund/Hadron-Daten exsitieren. 

\textbf{Für die Erstellung eines gemessenen Protonendatensatzes muss, aus dem Datensatz einer vermessenen $\gamma$-Quelle, durch einen geschickten Schnitt die Protonenereignisse heraussepariert werden. 
Denkbar wäre auch ein auf Monte-Carlo Daten trainiertes Modell zunächst einmal den Quelldatensatz nach Protonen suchen zu lassen, wobei die Monte-Carlo Missmatches erneut eingehen würden und aus diesem Grunde darauf verzichtet wird.}

Dementsprechend wird, anhand des trennstärksten Features $\theta^{2}$, versucht eine Separation von Daten einer Quelle in Protonen und Gammas durchzuführen. 
Die Trennstärke des trennstärksten Parameters $\theta^{2}$, im Vergleich zu allen anderen verfügbaren Parametern ist in Abbildung~\ref{fig:roc} dargestellt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Plots/theta_cut.pdf}
  \caption{$\theta^{2}$ Verteilung von simulierten Gamma und Protonen, sowie das Verhältnis von Gamma zu Protonen}
  \label{fig:thetacut}
\end{figure}
Durch Cuts auf der $\theta^{2}$ Verteilung soll ein möglischst reines Testset erstellt werden. 
In Abbildung~\ref{fig:thetacut} sind für Hadronen und Protonen die $\theta^{2}$ Verteilungen der Monte-Carlo Simulationen aufgetragen. 
Für kleine $\theta^{2}$ Werte ist das Gamma Signal um vielfaches größer und nimmt für größer werdende $\theta^{2}$ Werte kontinuierlich ab. 
Ab ein $\theta^{2}$ Wert von $0.5$ ist das Signal- zu Hintergrundverhältniss um ein zehntel kleiner.
\textbf{Aufgrund dessen das der wahre Untergund einerseits aus Hadronenen als auch wenigen Diffusen Gammas besteht, ist zu erwarten, dass die Gamma welche bei der Separation im gemessen Untergrund bleiben, die Klassifizierer nicht weiter negativ beeinflussen.}

% Zu beachten ist das Protonen zwar isotrop verteilt seien sollten, jedoch bei zu großen $\theta^{2}$-cuts die Detektoreigenschaften singnifikant werden. Um zu überprüfen inwiefern die Detektoreigenschaften vernachlässigt werden können ist in Abbildung~\ref{fig:corrtheta} die Signifikanz in Abhängigkeit des Parameters $\theta^{2}$ dargestellt.
\textbf{Um zu überprüfen ob die trainierten Modelle durch Schnitte in $\theta^{2}$ grundsätzlich schlechter werden , wird ein Modell traniert, bei derem Traningsdatensatz die Protonen Monte-Carlo in verschiedenen $\theta^{2}$ geschnitten wird. 
Die Signifikanz der unterschiedlich trainierten Modelle ist in Abbildung \ref{fig:corrtheta} dargestellt.}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{Plots/corr_sig_theta2.pdf}
  \caption{<+caption text+>}
  \label{fig:corrtheta}
\end{figure}
Dabei fällt auf das bis Werte gegen $\theta^{2} < 1$ die Signifikanz nicht wesentlich von $\theta$ abhängt. Bei Werten $\theta^{2} > 1$ nimmt die Signifikanz dementsprechend ab weil Detekoreigenschaften im Training vernachlässigt werden.

Dementsprechend scheinen $\theta^{2}$-Cuts zwischen \num{0.5} bis \num{1} für plausible. 
\textbf{Hier ist zu erkennen, dass für Monte Carlo basierte Modelle die Signifikanz der Quelle nicht abnimmt, wenn Protonen mit $\theta^{2} < 1$ aus dem Trainingsdatensatz entfernt werden. 
Desweiteren ist das Verhältniss an Gammas $\theta^{2} > 1$ im Untergrunddatensatz so gering das diese als diffuse Gamma angesehen werden können. (Beschränkung der Modelle -> fällt kaum ins Gewicht?)} 
Für die weitere Analyse wurde fortlaufend ein $\theta^{2}$-Cut von \num{0.5} gewählt. 
\section{Optimieren der Modelle}
Um zu evaluieren, welche Methode besser zwischen den Monte-Carlo oder gemessenen Daten separiert, werden zwei Datensätze erstellt. 
\begin{enumerate}
  \item \textbf{MC-Daten:} Monte-Carlo Gamma + Monte-Carlo Protonen
  \item \textbf{Mess-Daten:} Monte-Carlo Gamma + gemessene Protonen 
\end{enumerate}
Dabei wird auf dem Monte-Carlo Protonen Datensatz kein $\theta^{2}$-Cut durchgeführt weil dieser frei von Gamma seien sollte.
Mit den erstellten Trainings-Datensätze wird ein Klassifier trainiert und der AUC-Wert auf diesen bestimmt.
Bei einem Random Forest bieten neben einer hohen Anzahl an Bäumen (\texttt{n\_estimators}) die Tiefe der Bäume (\texttt{max\_depth}) und die Anzahl an Trainingsattributen (\texttt{max\_feature}) ein Maß der Beschränkung.

Für die Analyse wird die Anzahl der Bäume beim Random Forest auf \texttt{n\_estimators = 100} konstant gehalten. 
Mithilfe eines Parametergrids wird die optimale Konstellation der Parameter gesucht. 
\begin{figure}
  \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{Plots/parameter_crab.pdf}
	\caption{Messdaten}
	\label{fig:messGrid}
  \end{subfigure}
  \begin{subfigure}[b]{0.5\textwidth}
	\includegraphics[width=\textwidth]{Plots/parameter_monte.pdf}
	\caption{MC-Daten}
	\label{fig:mcGrid}
  \end{subfigure}
  \caption{Parameternetz zum Ermitteln der optimalen Parameter auf den unterschiedlichen Datensätzen.}
\end{figure}

Dabei fällt auf, dass sich die beiden Datensätze unterschiedlich gut trennen lassen.
Dadurch das auf echten Daten trainierte Modelle bei einer größeren Zahl an gezogenen Attributen erst ihren besten AUC-Wert erreichen, lässt sich folgern dass die Trennung komplexer ist.
Desweiteren ist der maximale AUC-Wert, bei dem auf Mess-Daten trainierten Datenset, größer als bei den Monte Carlo Daten. 

Die Bäume der Tiefe eins brauchen nicht optimiert werden, da sie aufgrund der stark begrenzten Tiefe nicht an Übertraining leiden.

\section{Signifikanz der Modelle}
Um ein Maß für die Güte der Modelle zu erhalten, wird die Signifikanz zweier unabhängiger Quellen bestimmt. 
Dafür werden die Klassifizierer einmal mit dem MC-Daten und einmal mit den Mess-Daten trainiert. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./tikz/conf/conf.pdf}
  \caption{<+caption text+>}
  \label{fig:<+label+>}
\end{figure}
Die Trainierten Modelle sollen daraufhin ein Konfidenzwert, für ein Datenset aus einer Quellregion, abgeben welche von den Daten Gamma bzw Protonen sind. 
Der Confidencewert spiegelt die Sicherheit des Klassifizierer wieder, dass das Event ein Gamma \texttt{1} oder ein Proton \texttt{0} ist. 
Aufgrund dessen das sich Gamma und Hadronen teilweise ähnlich sehen gibt der Klassifizierer eine Wahrescheinlichkeit zwischen 0 und 1 aus das es sich bei dem Event um ein Gamma oder Proton handelt.
Zur Bestimmung der Signifikanz werden verschiedene Schnitte auf dem Konfidenzwerten gemacht, dass es sich bei dem Signal um ein Gamma handelt.
Dabei wird die Menge oberhalb des Schnittes als Gamma und unterhalb als Proton klassifiziert. 
Die Klassifizierten Gammas setzen sich dementsprechend aus richtig Klassifizierten Gammas (TP) und Falsch klassifizierten Protonen (FP) zusammen. 
Die Größe der Signifikanz wird durch das Verhältniss von TP zu FP bestimmt, als auch durch die Größe der klassifizierten Gammas.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.88\textwidth]{./Plots/on_off_ratio.pdf}
  \caption{Roh Signifikanz von Crab}
  \label{fig:sig_crab}
\end{figure}
Ein grafisches Beispiel für die Signifikanz ist in Abbildung~\ref{fig:sig_crab} zu sehen. 
Abgebildet ist die $\theta^{2}$ Verteilung der On-Position und das mittel der fünf Off-Positionen.
Dabei wurde ein Konfidenzschnitt von 0 durchgeführt, was die Signifikanz der Rohdaten entspricht.
Die verwedete Quelle ist der Krebsnebel welche bereits ohne Klassifizierung eine Siknifikanz der Daten in einem Bereich von $\theta^{2} < 0.03$ beträgt \SI{21,4}{\sigma}.

Durch die Klassifizierung verschiedener Modelle wird versucht diese zu erhöhen. 
Dafür wird einerseits ein \texttt{Random Forest} benutzt, als auch ein \texttt{XGBOOSTClassifier} der Tiefe 1. 
Dabei hat der XGBOOSTClassifier den Vorteil, dass er aufgrund des Addativen Trainings noch einen Erkenntnissgewinn aus den Fehlkalssifizierung zieht, nachdem $n$ Bäume der Anzahl aller möglichen Featuren erstellt wurden.

Die Signifikanzen des Crab und Markarian Datensatzes werden jeweils auf der kompletten Größe des Datensatzes (Stand:00.00.0000) bestimmt. 
Desweiteren wurden beide Modelle mit jeweils einer Trainingsgröße von \num{100000} Ereignissen aus Gamma und Hadronen gleichermaßen trainiert. 
Der $\theta^{2}$ wird bei den Modellen konstant bei \num{0.03} gehalten.
\begin{table}[H]
  \centering
  \caption{warum werden die Striche nicht komplett durchgezogen und stoppen bei einer Multicolumn?}
  \begin{tabular}{l s s s s}
	\toprule
	& \multicolumn{2}{c}{Krebs Nebel}	& \multicolumn{2}{c}{Markarian} \\
	  \cmidrule(r){2-3} \cmidrule(l){4-5}
	  & Random & XGBoost 		& Random & XGBoost 	 \\
	& Forest & (Tiefe= 1) 	& Forest & (Tiefe= 1)\\
	unklassifizierte Daten & \multicolumn{2}{c}{\SI{21.4}{\sigma}}	& \multicolumn{2}{c}{\SI{17.1}{\sigma}} \\
	MC-Proton	 		   & \SI{41.9}{\sigma}	& \SI{41.3}{\sigma}	& \SI{35.5}{\sigma}	& \SI{35.6}{\sigma}\\
	gemessene Proton	   & \SI{32.9}{\sigma}	& \SI{37.8}{\sigma}	& \SI{23.6}{\sigma}	& \SI{35.2}{\sigma}\\
	\bottomrule
  \end{tabular}
  \label{tab:sign}
\end{table}
Die Signifikanz der beiden Quellen ist in Tabelle \ref{tab:sign} niedergeschrieben. 
Auffällig ist das im gegensatz zum Roc auc score die Signifikanz des mit den gemessenen Daten trainierten Klassifizierer geringer ist, als die derer die mit den MC-Daten trainiert wurden. 
Zu erwarten wäre gewesen, dass der Klassifizierer welche besser separiert auch eine höhere Signifikanz hat. 

Bei den \texttt{XGBOOSTClassifier} tritt dieser Effekt jedoch wesentlich schwächer als beim Random Forest auf. Dies deutet auf Übertraining des RandomForest hin. 
Möglicherweise wird der Klassifizierer nicht mehr darauf trainiert, zwischen Gamma und Protonen Ereignissen zu unterscheiden, sondern gemessene von Monte Carlo Events zu separieren.

\section{Confidence Score}
Neben der maximalen Signifikanz ist die Verteilung der Signifikanz in abhaengigkeit des Confidence wertes von interesse. 
In Abbildung \ref{fig:signconf} ist die Signifikanz fuer die einzelnen confidence werte dargestellt. 
Anhand der Form koennen Rueckschluesse ueber die Klassifier getroffen werden. 

Bei kleinen conf strebt die signifikanz gegen die des unklassifizierten Datensatzes.
Aufgrund der Groesse der als Gamma klassifitierten Events strebt die Signifikanz fuer grosse confidence werte gegen 0.
Dazwischen ist die Signifikanz ein Mass fuer die groesse des Testset in Abhaengigkeit der als richtig klassifizierten gammas.
\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./Plots/sig_mess_tree.pdf}
  \caption{Conf verteilung auf den Monte Carlo trainierten Daten fuere jeweils Random Forest und xgboost classifier}
  \label{fig:signconfMC}
\end{subfigure}
\begin{subfigure}[b]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./Plots/sig_mess_xgbc.pdf}
  \caption{Conf verteilung auf den gemessenen trainierten Daten fuere jeweils Random Forest und xgboost classifier}
  \label{fig:signconfMESS}
\end{subfigure}
\caption{Signifikanz der Modelle in Abhaengigkeit der verschiedenen Confidence Werte}
\label{fig:signconf}
\end{figure}

Vergleiche Form MonteCarlo Random Forest mit XGBOOSTClassifier 

Vergleiche Form gemssene Daten Random Forest mit XGBOOSTClassifier 

Ursachen fuer moegliche unterschiede.

In Abbildung \ref{fig:figdist} ist die Wahrscheinlichkeitsverteilund der Klassifizierten Events aufgetragen. 
Dabei ist auffaellig das ein grossteil der Events eindeutig der Klasse Proton zugeordnet werden kann. 
Im gegensatz dazu finden sich keine Events die Eindeutig der Klasse Gamma zuordnen lassen.
wann ist das der Fall ?
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{./Plots/conf.pdf}
  \caption{Moeglicherweise einmal mit Crab daten und einmal mit Sample aus 1:1 Gamma und hadronen}
  \label{fig:confdist}
\end{figure}
Dies liegt dem physikalischem Problem zugrunde das wenn ein Proton schon frueh beim Eintritt in ein $\pi^{0}$ Meson und einem $e^{+}$ zerfaellt kaum von einem Protonen schauer auseinander zu halten ist.
Dabei zerfaellt das $\pi^{0}$ Meson in zwei Gammas, ebenso wie das $e^{+}$ durch inverse Bremsstrahlung weitere Gammas erzeugt. 
Dies hatt zur Folge das Protonen Events die ueber einen anderen Zerfall aufschauern anders als Gamma events ausschauen, aber in jedem Gamma event auch ein wenig Proton steckt.
\begin{figure}[H]
  \centering
\begin{subfigure}[t]{0.3\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./images/Gamma.pdf}
  \caption{Gamma Ereigniss}
  \label{fig:gammaevent}
\end{subfigure}
\begin{subfigure}[t]{0.3\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./images/Hadron.pdf}
  \caption{Hadron Ereigniss mit aehnlichkeit zu einem Gamma Event}
  \label{fig:hadevent}
\end{subfigure}
\begin{subfigure}[t]{0.3\textwidth}
  \centering
  \includegraphics[width=\textwidth]{./images/Hadron2.pdf}
  \caption{Hadron Ereigniss ohne aehnlichkeit zu einem Gamma Event}
  \label{fig:had2event}
\end{subfigure}
\caption{Ereignisse in der Detektor Kamera vor dem Cleaning \cite{??}}
\label{fig:picevents}
\end{figure}
Der anschaulichkeit halber sind in Abbildung~\ref{fig:picevents} drei Events abgebildet.
Dabei weist das Proton Event in Abbildung~\ref{fig:hadevent} eine Gewisse aehnlichkeit zu dem Gamma Event (Abbildung~\ref{fig:gammaevent}) auf, wohingegen das Event in Abbildung~\ref{fig:had2event} wenig aehnlichkeit aufweist.
\section{Rekusive feature Elemination}
Da bekannt ist das der Monte Carlo simulierte Untergrund schlecht simuliert ist wird dieser mit dem gemessenen verglichen. 
Ziel ist es durch das entfernen von Featuren welche eine grossen Montecarlo missmatch haben die Seperation zu verbessern. 
Dabei soll das Modell nicht mehr zwischen gemessenen und monte Carlo simulierten Daten unterscheiden sonder die Klassifikation zwischen Gamma und Hadronen vornehmen.

Dafuer wird zunaechst ein Modell traininiert welches aus gleich vielen Teilen simulierten und gemessenen (nach section \ref{sec:} zusammengestellt) Protonenen besteht. 
Im Falle das das Modell die simulierten nicht von den gemessenen Protonen zu unterscheiden vermag, wird die Accuracy ungefaher 0.5 betragen. 
Die Accuracy betraegt jedoch auf dem kreuzvalidierten Datenset \num{0.99(9)}. 

Zur visualisierung der Feature bei denen sich echten von simulierten daten unterscheiden ist die Feature importance des trainierten Modells ist in Abbildung \ref{fig:featureimportance} durch die orangen balken dargestellt. 
In blau sind die gewichte der Feautre der Gamma hadron seperation dargestellt. 
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{./Plots/feature_elemination.pdf}
  \caption{<+caption text+>}
  \label{fig:<+label+>}
\end{figure}
Bei dem entfernen eines Features wird des Modells wird dementsprechend auch Informationsgehalt der Gamma Proton seperation verworfen. 
Dementsprechend muss ein Verhaeltniss zwischen Montecarlo missmatches einerseits und Informationsgehalt der Seperation anderseits gefunden werden.

Durch das entfernen der Feature \texttt{ph\_charge\_shower\_max}, \texttt{width}, \texttt{concentration\_two\_pixel} und \texttt{leakage2} laesst sich sowohl die Seperation zwischen simulierten und echten Daten minimieren als auch die Signifikanz der auf echten Daten trainierten Random Forest erhoehen.

\textbf{Confidence verteilung mal anschauen und die mit einem hohen conf wert genauer betrachten !!!!!!!!!!!!}
